{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4403e6d-399b-4896-b949-250f4d2a7b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: Epoch 1, Loss: 6.336004405897111, Accuracy: 0.37775\n",
      "text: Epoch 2, Loss: 2.4096026082597675, Accuracy: 0.4565\n",
      "text: Epoch 3, Loss: 2.083002632169053, Accuracy: 0.48591666666666666\n",
      "text: Epoch 4, Loss: 2.0588111116103827, Accuracy: 0.496875\n",
      "text: Epoch 5, Loss: 2.02466348452121, Accuracy: 0.5046\n",
      "text: Epoch 6, Loss: 2.0317517406325787, Accuracy: 0.5095416666666667\n",
      "text: Epoch 7, Loss: 2.018502006851137, Accuracy: 0.5134642857142857\n",
      "text: Epoch 8, Loss: 2.032102601151913, Accuracy: 0.515\n",
      "text: Epoch 9, Loss: 2.0060608965232967, Accuracy: 0.5180833333333333\n",
      "text: Epoch 10, Loss: 2.007508797062561, Accuracy: 0.52055\n",
      "text: Epoch 11, Loss: 2.0191653323443606, Accuracy: 0.5227045454545455\n",
      "text: Epoch 12, Loss: 2.0169910898227243, Accuracy: 0.5237291666666667\n",
      "text: Epoch 13, Loss: 2.021630831762217, Accuracy: 0.5245384615384615\n",
      "text: Epoch 14, Loss: 2.008266220808029, Accuracy: 0.5258035714285715\n",
      "text: Epoch 15, Loss: 2.0263830743581055, Accuracy: 0.52645\n",
      "text: Epoch 16, Loss: 2.0107314344383775, Accuracy: 0.527046875\n",
      "text: Epoch 17, Loss: 2.0148158136177807, Accuracy: 0.5273382352941176\n",
      "text: Epoch 18, Loss: 2.0117518237009646, Accuracy: 0.5283333333333333\n",
      "text: Epoch 19, Loss: 2.04051803637296, Accuracy: 0.5286578947368421\n",
      "text: Epoch 20, Loss: 2.0223152064997705, Accuracy: 0.529225\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class TextModel(nn.Module):\n",
    "    def __init__(self, text_input_dim, hidden_dim):\n",
    "        super(TextModel, self).__init__()\n",
    "        self.fc = nn.Linear(text_input_dim, hidden_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        return out\n",
    "\n",
    "# class ImageModel(nn.Module):\n",
    "#     def __init__(self, image_input_dim, hidden_dim):\n",
    "#         super(ImageModel, self).__init__()\n",
    "#         self.fc = nn.Linear(image_input_dim, hidden_dim)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         out = self.fc(x)\n",
    "#         return out\n",
    "\n",
    "# class FusionModel(nn.Module):\n",
    "#     def __init__(self, hidden_dim, num_classes):\n",
    "#         super(FusionModel, self).__init__()\n",
    "#         self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "    \n",
    "#     def forward(self, text_features, image_features):\n",
    "#         fused_features = torch.cat((text_features, image_features), dim=1)\n",
    "#         out = self.fc(fused_features)\n",
    "#         return out\n",
    "\n",
    "# 定义模型参数\n",
    "text_input_dim = 300  # 假设文本特征维度为300\n",
    "# image_input_dim = 512  # 假设图像特征维度为512\n",
    "hidden_dim = 256  # 隐层维度\n",
    "num_classes = 3  # 类别数量：positive, neutral, negative\n",
    "\n",
    "text_model = TextModel(text_input_dim, hidden_dim)\n",
    "# image_model = ImageModel(image_input_dim, hidden_dim)\n",
    "# fusion_model = FusionModel(hidden_dim*2, num_classes)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "def get_text_features(guid):\n",
    "    # 假设您使用的是预训练的词向量模型（如GloVe）来表示文本\n",
    "    # 这里仅作示例，实际上需要根据您的具体情况进行修改\n",
    "    text_file_path = \"data/{}.txt\".format(guid)\n",
    "    with open(text_file_path, \"r\", encoding=\"latin-1\") as file:\n",
    "        text_data = file.read()\n",
    "    \n",
    "    # 在这里进行文本特征提取的相关操作，例如文本预处理、词嵌入等\n",
    "    # 这里使用随机向量作为示例\n",
    "    random_text_features = torch.randn(1, 300)  # 假设文本特征维度为300\n",
    "    \n",
    "    return random_text_features\n",
    "\n",
    "# def get_image_features(guid):\n",
    "#     # 假设使用的是预训练的卷积神经网络（如ResNet）来提取图像特征\n",
    "#     image_file_path = \"data/{}.jpg\".format(guid)\n",
    "    \n",
    "#     # 在这里进行图像特征提取的相关操作，例如图像预处理、CNN网络等\n",
    "#     # 这里使用随机向量\n",
    "#     random_image_features = torch.randn(1, 512)  # 假设图像特征维度为512\n",
    "    \n",
    "#     return random_image_features\n",
    "\n",
    "\n",
    "# 定义训练数据和标签\n",
    "# train_data = [(\"4597\", \"negative\"), (\"2020\", \"positive\"), (\"4784\", \"neutral\")]  # 根据实际数据填充\n",
    "\n",
    "file_train = \"train.txt\"\n",
    "\n",
    "# 读取文件内容\n",
    "with open(file_train, \"r\") as file:\n",
    "    lines = file.readlines()[1:]\n",
    "    \n",
    "# 构建训练数据列表\n",
    "train_data = []\n",
    "for line in lines:\n",
    "    # 解析每一行数据\n",
    "    guid, tag = line.strip().split(\",\")\n",
    "    train_data.append((guid, tag))\n",
    "\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(list(text_model.parameters()), lr=0.001)\n",
    "\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(20):  # 假设训练轮数为10\n",
    "    running_loss = 0.0\n",
    "    for data in train_data:\n",
    "        guid, tag = data\n",
    "        \n",
    "        # 假设文本特征提取函数为get_text_features，图像特征提取函数为get_image_features\n",
    "        text_features = get_text_features(guid)  \n",
    "#         image_features = get_image_features(guid)\n",
    "        \n",
    "        # 将标签转换为对应的数字编码\n",
    "        if tag == \"positive\":\n",
    "            label = 0\n",
    "        elif tag == \"neutral\":\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 2\n",
    "        \n",
    "        # 清零梯度、前向传播、计算损失、反向传播、更新参数\n",
    "        optimizer.zero_grad()\n",
    "        text_output = text_model(text_features)\n",
    "#         image_output = image_model(image_features)\n",
    "#         fusion_output = fusion_model(text_output, image_output)\n",
    "        loss = criterion(text_output, torch.tensor([label]))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted_label = torch.max(text_output, dim=1)\n",
    "        correct_predictions += (predicted_label == label).sum().item()\n",
    "        total_predictions += 1\n",
    "    \n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    \n",
    "    # 打印每个epoch的损失\n",
    "    print(\"text: Epoch {}, Loss: {}, Accuracy: {}\".format(epoch+1, running_loss/len(train_data), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0501ee62-94e8-4086-bd60-cc68cf654d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: Epoch 1, Loss: 3.212866681130603, Accuracy: 0.37675\n",
      "image: Epoch 2, Loss: 1.343382971957326, Accuracy: 0.4385\n",
      "image: Epoch 3, Loss: 1.131471903196536, Accuracy: 0.4658333333333333\n",
      "image: Epoch 4, Loss: 1.099324765439378, Accuracy: 0.4799375\n",
      "image: Epoch 5, Loss: 1.1045890174414963, Accuracy: 0.4869\n",
      "image: Epoch 6, Loss: 1.0914594444050454, Accuracy: 0.4895833333333333\n",
      "image: Epoch 7, Loss: 1.1082705853204242, Accuracy: 0.4925357142857143\n",
      "image: Epoch 8, Loss: 1.0939388573623727, Accuracy: 0.49571875\n",
      "image: Epoch 9, Loss: 1.0908300493555143, Accuracy: 0.498\n",
      "image: Epoch 10, Loss: 1.1004334159248974, Accuracy: 0.49895\n",
      "image: Epoch 11, Loss: 1.102211472969735, Accuracy: 0.5006363636363637\n",
      "image: Epoch 12, Loss: 1.0900430620028638, Accuracy: 0.5016666666666667\n",
      "image: Epoch 13, Loss: 1.1073447633082978, Accuracy: 0.5021346153846153\n",
      "image: Epoch 14, Loss: 1.0957331389700995, Accuracy: 0.503125\n",
      "image: Epoch 15, Loss: 1.0955094764516689, Accuracy: 0.5041166666666667\n",
      "image: Epoch 16, Loss: 1.0954960680629593, Accuracy: 0.504828125\n",
      "image: Epoch 17, Loss: 1.0890344521168154, Accuracy: 0.5058235294117647\n",
      "image: Epoch 18, Loss: 1.0988972788692917, Accuracy: 0.5059722222222223\n",
      "image: Epoch 19, Loss: 1.0797192326809746, Accuracy: 0.506578947368421\n",
      "image: Epoch 20, Loss: 1.1022142103924415, Accuracy: 0.50685\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# class TextModel(nn.Module):\n",
    "#     def __init__(self, text_input_dim, hidden_dim):\n",
    "#         super(TextModel, self).__init__()\n",
    "#         self.fc = nn.Linear(text_input_dim, hidden_dim)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         out = self.fc(x)\n",
    "#         return out\n",
    "\n",
    "class ImageModel(nn.Module):\n",
    "    def __init__(self, image_input_dim, hidden_dim):\n",
    "        super(ImageModel, self).__init__()\n",
    "        self.fc = nn.Linear(image_input_dim, hidden_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        return out\n",
    "\n",
    "# class FusionModel(nn.Module):\n",
    "#     def __init__(self, hidden_dim, num_classes):\n",
    "#         super(FusionModel, self).__init__()\n",
    "#         self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "    \n",
    "#     def forward(self, text_features, image_features):\n",
    "#         fused_features = torch.cat((text_features, image_features), dim=1)\n",
    "#         out = self.fc(fused_features)\n",
    "#         return out\n",
    "\n",
    "# 定义模型参数\n",
    "# text_input_dim = 300  # 假设文本特征维度为300\n",
    "image_input_dim = 512  # 假设图像特征维度为512\n",
    "hidden_dim = 256  # 隐层维度\n",
    "num_classes = 3  # 类别数量：positive, neutral, negative\n",
    "\n",
    "# text_model = TextModel(text_input_dim, hidden_dim)\n",
    "image_model = ImageModel(image_input_dim, hidden_dim)\n",
    "# fusion_model = FusionModel(hidden_dim*2, num_classes)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# def get_text_features(guid):\n",
    "#     # 假设您使用的是预训练的词向量模型（如GloVe）来表示文本\n",
    "#     # 这里仅作示例，实际上需要根据您的具体情况进行修改\n",
    "#     text_file_path = \"data/{}.txt\".format(guid)\n",
    "#     with open(text_file_path, \"r\", encoding=\"latin-1\") as file:\n",
    "#         text_data = file.read()\n",
    "    \n",
    "#     # 在这里进行文本特征提取的相关操作，例如文本预处理、词嵌入等\n",
    "#     # 这里使用随机向量作为示例\n",
    "#     random_text_features = torch.randn(1, 300)  # 假设文本特征维度为300\n",
    "    \n",
    "#     return random_text_features\n",
    "\n",
    "def get_image_features(guid):\n",
    "    # 假设使用的是预训练的卷积神经网络（如ResNet）来提取图像特征\n",
    "    image_file_path = \"data/{}.jpg\".format(guid)\n",
    "    \n",
    "    # 在这里进行图像特征提取的相关操作，例如图像预处理、CNN网络等\n",
    "    # 这里使用随机向量\n",
    "    random_image_features = torch.randn(1, 512)  # 假设图像特征维度为512\n",
    "    \n",
    "    return random_image_features\n",
    "\n",
    "\n",
    "# 定义训练数据和标签\n",
    "# train_data = [(\"4597\", \"negative\"), (\"2020\", \"positive\"), (\"4784\", \"neutral\")]  # 根据实际数据填充\n",
    "\n",
    "file_train = \"train.txt\"\n",
    "\n",
    "# 读取文件内容\n",
    "with open(file_train, \"r\") as file:\n",
    "    lines = file.readlines()[1:]\n",
    "    \n",
    "# 构建训练数据列表\n",
    "train_data = []\n",
    "for line in lines:\n",
    "    # 解析每一行数据\n",
    "    guid, tag = line.strip().split(\",\")\n",
    "    train_data.append((guid, tag))\n",
    "\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(list(image_model.parameters()), lr=0.001)\n",
    "\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(20):  # 假设训练轮数为10\n",
    "    running_loss = 0.0\n",
    "    for data in train_data:\n",
    "        guid, tag = data\n",
    "        \n",
    "        # 假设文本特征提取函数为get_text_features，图像特征提取函数为get_image_features\n",
    "#         text_features = get_text_features(guid)  \n",
    "        image_features = get_image_features(guid)\n",
    "        \n",
    "        # 将标签转换为对应的数字编码\n",
    "        if tag == \"positive\":\n",
    "            label = 0\n",
    "        elif tag == \"neutral\":\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 2\n",
    "        \n",
    "        # 清零梯度、前向传播、计算损失、反向传播、更新参数\n",
    "        optimizer.zero_grad()\n",
    "#         text_output = text_model(text_features)\n",
    "        image_output = image_model(image_features)\n",
    "#         fusion_output = fusion_model(text_output, image_output)\n",
    "        loss = criterion(image_output, torch.tensor([label]))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted_label = torch.max(image_output, dim=1)\n",
    "        correct_predictions += (predicted_label == label).sum().item()\n",
    "        total_predictions += 1\n",
    "    \n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    \n",
    "    # 打印每个epoch的损失\n",
    "    print(\"image: Epoch {}, Loss: {}, Accuracy: {}\".format(epoch+1, running_loss/len(train_data), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe2e167-5bbb-42d1-a8de-49f5c83ae993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
